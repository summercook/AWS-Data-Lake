
# This projects creates a rational database from two data sets on Amazon Web Services.

## Purpose:
The purpose of this project is to create a cloud based database that allows sparkify to analyse many aspects of its user's listening behavior. Aggregations can be performed using different units of time, location, user demographics and music preferences, that will enable sparkify to understand how to respond to its customers' needs.

## Data sets:
The first dataset is a subset of real data from the Million Song Dataset. The second dataset consists of log files in JSON format generated by an event simulator. Both are saved on a public S3 bucket on AWS.

## Structure of the database:
### Fact Table
- songplays: records in log data associated with song plays i.e. records with page NextSong
Column names: songplay_id, start_time, user_id, level, song_id, artist_id, session_id, location, user_agent
### Dimension Tables
- users: users in the app
Column names: user_id, first_name, last_name, gender, level
- songs: songs in music database
Column names: song_id, title, artist_id, year, duration
- artists: artists in music database
Column nmaes: artist_id, name, location, latitude, longitude
- time: timestamps of records in songplays broken down into specific units
Column names: start_time, hour, day, week, month, year, weekday


## Submitted files for the creation of the data pipeline:
1. sql_queries.py
2. create_tables.py
3. etl.py
4. dwh.cfg


## Discription of each file:
1. sql_queries.py: Contains SQL queries to:
- drop tables,
- create staging and database tables,
- copy data from S3 bucket to staging tables and
- insert values from staging tables into the database tables.
2. create_tables.py: Runs functions for connecting to the AWS cluster and executing the SQL queries in sql_queries.py that drop all existing tables and creates 7 empty tables.
3. etl.py: The pipeline for accessing the files stored in the log and song files in the S3 bucket, copy it to the 2 staging tables and insert from the staging tables into the 5 database tables.
4. dwh.cfg: Contains identifiers of the cluster
